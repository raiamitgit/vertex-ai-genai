{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afBCLvNQ6ZKQ"
      },
      "source": [
        "# Vertex AI: Extract Tables from PDF using Gemini Multimodal Models\n",
        "\n",
        "This notebook demonstrating how to use Google's Gemini multimodal models via Vertex AI to extract data from tables within PDF documents.\n",
        "\n",
        "The script showcases two primary capabilities:\n",
        "\n",
        "1.  **Identifying** pages containing tables and plots within a PDF, outputting the results in a structured JSON format.\n",
        "2.  **Extracting** the content of a *specific* table (identified by its page number and caption) into Markdown format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSl4EOCSv-bg"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The notebook leverages the `google-genai` Python SDK configured to work with Vertex AI. It performs the following steps:\n",
        "\n",
        "1.  **Setup & Authentication:** Installs necessary libraries (`google-genai`, `google-cloud-aiplatform`) and authenticates with Google Cloud.\n",
        "2.  **Configuration:** Sets required Google Cloud project details, Vertex AI location (region), the specific Gemini Model ID to use, and the Google Cloud Storage (GCS) location of the input PDF file.\n",
        "3.  **Multimodal Prompting:** Sends requests to the specified Gemini model (works with 2.0 and 2.5 models):\n",
        "    *   The input PDF document provided as a GCS URI.\n",
        "    *   A text prompt guiding the model on the desired task.\n",
        "4.  **Structured Output (JSON):** Demonstrates how to define an output schema and configure the API call to force the model to respond in a specific JSON format.\n",
        "5.  **Targeted Extraction (Markdown):** Shows how to prompt the model to find a specific table based on context (page number, caption) and extract its content into a human-readable Markdown format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoIvobSZwXN0"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before running this script, ensure you have the following:\n",
        "\n",
        "1.  **Google Cloud Project:** A Google Cloud Platform project with billing enabled.\n",
        "2.  **APIs Enabled:** The **Vertex AI API** must be enabled in your GCP project.\n",
        "3.  **Vertex AI Region:** Choose a Vertex AI region that supports the desired Gemini Model (e.g., `us-central1`). Note this down for the `LOCATION` variable.\n",
        "4.  **Gemini Model Access:** Ensure the chosen `MODEL_ID` (e.g., `gemini-2.5-pro-exp-03-25`) is available in your selected region and project.\n",
        "5.  **Google Cloud Storage (GCS):**\n",
        "    *   A GCS bucket within your project.\n",
        "    *   The PDF document you want to process must be uploaded to this bucket. Note down the **GCS URI** (e.g., `gs://your-bucket-name/path/to/your-document.pdf`).\n",
        "6.  **Required Libraries:** Install the necessary Python packages:\n",
        "    ```bash\n",
        "    pip install -U google-genai google-cloud-aiplatform google-auth\n",
        "    ```\n",
        "7.  **Authentication:** You need to be authenticated to Google Cloud. Methods include:\n",
        "    *   **Google Colab:** The notebook uses `google.colab.auth.authenticate_user()`.\n",
        "    *   **Local Development/VM/Cloud Shell:** Use the Google Cloud SDK (`gcloud`):\n",
        "        ```bash\n",
        "        gcloud auth application-default login\n",
        "        ```\n",
        "    *   **Service Account:** Set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path of your service account key file.\n",
        "8.  **Permissions:** Ensure the authenticated principal (user or service account) has sufficient IAM permissions, typically including:\n",
        "    *   `Vertex AI User` (roles/aiplatform.user)\n",
        "    *   `Storage Object Viewer` (roles/storage.objectViewer) on the input GCS file/bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BYuuDC6ZAS"
      },
      "source": [
        "## Basic Setup\n",
        "Install dependencies and authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIuv2L3TTGlH"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google\n",
        "!pip install -U -q google.genai\n",
        "!pip install -U -q google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7s5U3Bsfh_X"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import base64\n",
        "from typing import Optional, Sequence\n",
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peJA3hmzQF4w"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYfLKD3iKRDO"
      },
      "outputs": [],
      "source": [
        "# Configure GCP environment\n",
        "PROJECT_ID = \"my-gcp-project-id\"\n",
        "LOCATION = \"us-central1\"\n",
        "# MODEL_ID = \"gemini-2.5-pro-exp-03-25\"\n",
        "MODEL_ID = \"gemini-2.0-flash-001\"\n",
        "GCS_FILE_PATH = \"gs://my-bucket/my-folder/my-file.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb2CO5rtSB5z"
      },
      "source": [
        "## Document processing with Gemini\n",
        "Extract structured table information using gemini models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1wCI4U4SG2V"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, model, output_schema=None):\n",
        "  \"\"\"Sends a prompt and a PDF from GCS to a Gemini for processing.\n",
        "\n",
        "  Initializes a connection to the Vertex AI GenAI service using\n",
        "  PROJECT_ID and LOCATION. It attaches a PDF document specified by the\n",
        "  global GCS_FILE_PATH along with the provided text prompt.\n",
        "\n",
        "  The request is configured to receive a streaming JSON response that adheres\n",
        "  to a specific schema: an array of page objects. Each page object should\n",
        "  contain 'page_number' (integer), 'tables' (an array of strings/captions),\n",
        "  and 'plots' (an array of strings/captions). The schema explicitly requires\n",
        "  'tables' and 'plots' for each page object in the response.\n",
        "\n",
        "  The function prints the text content of the response chunks to standard\n",
        "  output as they are received. It does not return any value.\n",
        "\n",
        "  Args:\n",
        "      prompt (str): The text prompt to accompany the PDF document.\n",
        "      model (str): The identifier string for the generative model to be used\n",
        "                   (e.g., 'gemini-2.5-pro-exp-03-25').\n",
        "  \"\"\"\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=PROJECT_ID,\n",
        "      location=LOCATION,\n",
        "  )\n",
        "\n",
        "  doc_attachment = types.Part.from_uri(\n",
        "      file_uri=GCS_FILE_PATH,\n",
        "      mime_type=\"application/pdf\",\n",
        "  )\n",
        "\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        doc_attachment,\n",
        "        types.Part.from_text(text=prompt)\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        "\n",
        "  if output_schema:\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "      temperature = 0.1,\n",
        "      top_p = 0.8,\n",
        "      candidate_count = 1,\n",
        "      max_output_tokens = 2048,\n",
        "      response_modalities = [\"TEXT\"],\n",
        "      response_mime_type = \"application/json\",\n",
        "      response_schema = output_schema\n",
        "    )\n",
        "  else:\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "      temperature = 0.1,\n",
        "      top_p = 0.8,\n",
        "      candidate_count = 1,\n",
        "      max_output_tokens = 2048,\n",
        "      response_modalities = [\"TEXT\"]\n",
        "    )\n",
        "\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    print(chunk.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAtAb7piAKN6"
      },
      "source": [
        "### Identify tables and charts in the documents\n",
        "\n",
        "\n",
        "Sends a detailed prompt to a Gemini instructing the model to analyze a document and extract information about pages containing tables and plots, requiring a specific, structured JSON output.\n",
        "\n",
        "Provide the specification of the output json schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn0sA1yZR28Q",
        "outputId": "822d1481-9679-4951-ce2a-d406d5633ec9"
      },
      "outputs": [],
      "source": [
        "# Identify tables in the document\n",
        "prompt = \"\"\"identify all the pages in the document that contains tables and plots/charts.\n",
        "If there are no tables or plots on a page, skip it.\n",
        "This is a very sensitive document and any page, table or plot can not be skipped.\n",
        "Output the response in json format.\n",
        "\"\"\"\n",
        "output_schema = { # This schema definition matches the final agreed-upon structure\n",
        "        \"type\": \"array\",\n",
        "        \"items\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "            \"page_number\": {\n",
        "              \"type\": \"integer\"\n",
        "            },\n",
        "            \"tables\": {\n",
        "              \"type\": \"array\",\n",
        "              \"items\": {\n",
        "                \"type\": \"string\"\n",
        "              }\n",
        "            },\n",
        "            \"plots\": {\n",
        "              \"type\": \"array\",\n",
        "              \"items\": {\n",
        "                \"type\": \"string\"\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          # Only 'tables' and 'plots' are marked as 'required'.\n",
        "          # Consider adding \"page_number\" here if all pages should always be present in response.\n",
        "          \"required\": [\n",
        "            \"tables\",\n",
        "            \"plots\"\n",
        "          ]\n",
        "        }\n",
        "      }\n",
        "\n",
        "generate(prompt, MODEL_ID, output_schema=output_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeAw5EIKAPY_"
      },
      "source": [
        "### Extract structured data from tables in markdown format\n",
        "For demonstration a single table is bein used here as example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwvp7_iva8K4",
        "outputId": "746a3015-6476-432a-eb81-45887b485f2d"
      },
      "outputs": [],
      "source": [
        "# Specify the page number and caption of the table or the plot\n",
        "page_number = 4\n",
        "object_caption = \"Table 1. Demographic and Baseline Disease Characteristics of the Patients.*\"\n",
        "\n",
        "# Parse 1 table\n",
        "prompt = f\"\"\"Analyze the provided document to locate the specific table or plot/chart found on page {page_number} which is identified by the exact caption \"{object_caption}\".\n",
        "Accurately extract the full data content of this table, ensuring you capture all headers and data cells.\n",
        "Format the output in a pretty markdown format with equal spacing in all rows.\n",
        "\"\"\"\n",
        "generate(prompt, MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta0YFp-Zy1ON"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
